---
output: pdf_document
---
#Results
```{r, echo=F}
library(xtable)
library(Matrix)
###############################################
# temporarily load data from REPORT DIRECTORY #
# this is for initially writting the file     #
# change to load from TOP DIRECTORY when done #
###############################################

load(file = "../../data/lm-model.RData")
load(file = "../../data/ridge-models.RData")
load(file = "../../data/lasso-models.RData")
load(file = "../../data/pls-models.RData")
load(file = "../../data/pcr-models.RData")

# read in original data, tests and training sets as well
data = as.matrix(read.csv("../../data/scaled-credit.csv", row.names = 1))
x.train = as.matrix(read.csv("../../data/xtrain.csv", row.names = 1))
y.train = as.matrix(read.csv("../../data/ytrain.csv", row.names = 1))
x.test = as.matrix(read.csv("../../data/xtest.csv", row.names = 1))
y.test = as.matrix(read.csv("../../data/ytest.csv", row.names = 1))
```
Next we consider the training set mean squared errors of each model, to better address overall model effectiveness:
```{r, results = "asis", echo = FALSE}
options(xtable.comment = FALSE)
# may add this chunk to RESULTS section instead of ANALYSIS
Model = c("OLS", "Ridge", "Lasso", "PCR", "PLS")
TestMSE = c(linearMSE, cvRidgeMSE, cvLassoMSE, cvPcrMSE, cvPlsMSE)
mseDF = cbind(Model, TestMSE)
mseTable = xtable(mseDF, caption = "Model Test MSE", digits = 5)
print(mseTable, type = "latex", caption.placement = "top")
```

From this it is clear that OLS was the worst method, which we expected since our data clearly has correlated regressors (ex: Age and Education). The best methods were the ridge and lasso shrinkage methods, which yielded test MSEs of `r cvRidgeMSE` and `r cvLassoMSE` respectively. The next best methods were the PCA and PLS dimmension reduction methods, which yielded test MSEs of `r cvPcrMSE` and `r cvPcrMSE`.
